# 北工大图形学-期中后

## Animation Update

### 画面撕裂

众所周知，像让人眼觉得物体在动，至少需要24帧 (FPS - Frames Per Second) 。当刷新率快于 GPU 渲染时，可能会导致画面撕裂 (Screen Tearing) ，解决这个问题通常有几种方法：
1. 垂直同步 V-Sync: 强制 GPU 等待显示器刷新，可以消除撕裂，但可能引入输入延迟。
2. 双/三重缓冲 Double/Triple Buffering：使用多个缓冲区（framebuffer）。GPU 在后缓冲区中绘制，而显示器显示前缓冲区的内容。绘制完成后，两者交换。

如果产生掉帧 (Frame Drop) ，可以增加帧率，每秒60帧就不赖。

### 模拟运动

对于每帧，我们计算：
1. 物体新的 transformations
2. 新的光照（有时）
3. 新的颜色/材质（偶尔）
4. 新的几何体（很少）

我们将物体的位置 `p` 视为时间 `t` 的函数 。在每一帧，我们都会为物体计算新的变换。

- 对于刚体（比如一个纯纯长方体）运动的模拟，我们可以简单将其运动分解为平移和旋转。比如对于一个火车头，我们仅让起往前走，然后让它可以转弯，就可以模拟一个运动。

- 对于关节式的模型 (articulated model) ：人类或动物不像火车那样是一个刚体，而是关节式的。它们由骨骼（Bones）和连接骨骼的关节（Joints）组成。

#### 树状结构

在图形学中，骨骼是指模型上一个可以被单独变换的部分，每个骨骼都有自己的局部坐标系；关节是连接两个骨骼的点，允许骨骼相对于彼此旋转或移动，关节的自由度 Freedom 决定了关节的可以转动的角度。

当我们尝试去绘制一个人的时候，我们会先定一个根物体，然后在根物体上不断添加子物体，让根物体带动子物体运动，以方便实现一个部位带动另一个部位的效果。举个例子，根物体是人的盆骨，它有子物体躯干，躯干有子物体大臂，大臂有子物体小臂，如此类推，当躯干移动的时候，子物体手臂会自然地跟着动起来。

#### 坐标系变换链 Transformation Chain

既然我们已经知道人体的树状结构，那实际上我们该如何去实现呢？

我们让每个部位都在它父节点的局部坐标系 (Local Coordinate System) 中定义。

比方说，我们要去绘制左手：
1. 左手定义在前臂 (Forearm) 的坐标系里。
2. 前臂定义在上臂 (Upper Arm) 的坐标系里。
3. 上臂定义在躯干 (Chest) 的坐标系里。
4. 躯干定义在骨盆 (Pelvis) 的坐标系里。
5. 骨盆定义在世界 (World) 坐标系里。

那么要画出左手在世界中的位置，我们就需要把不同部位变换矩阵连乘起来：

$$M_{world} = M_{pelvis} \cdot M_{chest} \cdot M_{upperArm} \cdot M_{forearm} \cdot M_{hand}$$

在代码中实现我们需要用到栈 Stack 后进先出 (LIFO) 的特性来保存和恢复变换矩阵。例如：
- `glPushMatrix()`: 备份当前状态
- `glPopMatrix()`: 恢复之前的状态

其实这本身也是一个深度优先搜索 DFS 的过程：
```kotlin
// 遍历树状结构
fun drawNode(node: Node) {
    glPushMatrix() // 备份当前矩阵
    glMultMatrix(node.transform) // 应用当前节点的变换
    drawGeometry(node.geometry) // 绘制当前节点的几何体

    // 递归绘制子节点
    for (child in node.children) {
        drawNode(child) 
    }
    glPopMatrix() // 恢复之前的矩阵
}
```

#### 姿态生成 Pose Generation

1. 正向运动学 Forward Kinematics, FK:

    - 给定每个关节的角度，计算末端执行器（如手或脚）的位置。
    - 但你很多时候很难确定每个关节要旋转多少，才能让手到达某个位置。

2. 逆向运动学 Inverse Kinematics, IK:

    - 确定目标位置（End Effector），通过算法（Solver）反推一连串部位（Joint Chains）的旋转角度。
    - 性能开销大于 FK。

3. 动作捕捉 Motion Capture, Mocap

    - 只能动捕人或动物。
    - 贵。


4. 物理模拟 Physics Simulation:

    - 设置好重力、摩擦力、质量，让物理引擎去算。

    - 很难调整出精细的动作。

5. 关键帧插值 Keyframe Interpolation:

    - 只做出几个关键帧，通过计算机计算出中间过渡。
    - 需要好的动画师。

## Physical & Biology Update

光在现实世界满足波粒二象性，其波长会影响我们对其颜色的感知，在图形学中我们把光看作是延直线传播的粒子流。

人眼的视网膜上主要有两种细胞帮我们形成图像：
- 视杆细胞 Rods：大约1.2亿个，对光非常敏感，但只能感知亮度（画面黑白），且分辨率低。
- 视锥细胞 Cones：大约600万个，负责颜色感知和更细致的画面。

人的视锥细胞只有三中，分别对红 Red、绿 Green、蓝 Blue 三种光波长最敏感，所以为了模拟现实世界的颜色，只要混合不同比例的 R、G、B 三种光，大脑就会以为自己看到了某种特定的颜色。

光在视网膜上的强度是一个连续函数 $I(x,y)$，计算机是离散机器，无法处理无限精度的函数。因此，为了模拟现实中的光强，我们对屏幕上的每个像素，计算对应区域里光照的积分：

$$P_{ij}=\int_{...}I(x,y)dy~dx$$

像素 $P_{ij}$ 是该区域内所有光强度的总和。

这里介绍三种渲染图像的方式：
1. 光线追踪 Ray Tracing：从摄像机向场景中的每个像素发射光线，追踪这些光线与物体的碰撞、反射和折射。
    - 能够自然地处理阴影、反射、透明度和全局光照 Global Illumination
    - 通常使用递归算法来计算光线的多次反弹
    - 计算成本昂贵，速度慢

2. 投影渲染 Projective Rendering / Rasterization：将 3D 物体表示为三角形网格 Mesh of triangles。
    - 使用矩阵变换将 3D 坐标直接投影到 2D 屏幕坐标上
    - 通过插值填充三角形内部的像素颜色（光栅化）
    - 通常使用 Phong 或 Gouraud 等局部光照模型，速度快，但难以反射和全局光影

3. 基于图像的渲染 Image-Based Rendering, IBR：不使用 3D 模型，而是通过拼接和插值现有的照片来生成新视角。
    - 逼真，因为源头就是照片
    - 像是 Google 街景 (Street View)、VR 全景看房
    - 静态，但很难移动物体或改变光照，交互性差

## Lighting & Shadows


